{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/june-oh/2023_AI_Academy_ASR/blob/main/1_Audio_file_handling_using_torchaudio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZISnubabp6A"
      },
      "source": [
        "# 1. TorchAudio를 이용한 음성파일 처리\n",
        "\n",
        "## Python Audio Manipulation Packages\n",
        "### Torchaudio\n",
        "<img src=\"https://github.com/pytorch/audio/raw/main/docs/source/_static/img/logo.png\" height=120>\n",
        "\n",
        "The aim of torchaudio is to apply PyTorch to the audio domain. \n",
        "\n",
        "\n",
        "\n",
        "### Librosa \n",
        "\n",
        "<img src=\"https://github.com/librosa/librosa/raw/main/docs/img/librosa_logo_text.svg\" heigt=120>\n",
        "\n",
        "A python package for music and audio analysis.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### library import\n",
        "- `torch` : Deep learning 라이브러리, 간편하게 모델을 설계하고 학습 가능(PyTorch)\n",
        "- `torchaudio` : torch tensor형식으로 오디오를 다룰 수 있는 라이브러리\n",
        "- `pandas` : dataframe, csv, excel - table 데이터를 다루는 라이브러리\n",
        "- `matplotlib` : 시각화용 라이브러리 \n",
        "- `IPython.display` : IPython 위젯을 사용할 수 있는 라이브러리\n",
        "- `pathlib` : 경로 관련 라이브러리, 파일의 경로를 쉽게 사용가능\n"
      ],
      "metadata": {
        "id": "39uG4b-Xmw1U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtCpLDf_bmkf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchaudio     \n",
        "import torchaudio.transforms as T\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipd\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Version Check"
      ],
      "metadata": {
        "id": "BkXXGyYcTPo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#version check"
      ],
      "metadata": {
        "id": "pQ_IVwlGTL1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzewrDLLpTA7"
      },
      "source": [
        "# Load Audio File\n",
        "## Data : free-spoken-digit-dataset\n",
        "\n",
        "음성 버전의 MNIST dataset\n",
        "\n",
        "https://github.com/Jakobovski/free-spoken-digit-dataset\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1yEjXMS5-KTrYriyPhrSaJqeneBTStao_\">\n",
        "\n",
        "### Current status\n",
        "- 6 speakers\n",
        "- 3,000 recordings (50 of each digit per speaker)\n",
        "- English pronunciations\n",
        "### Organization\n",
        "Files are named in the following format: `{digitLabel}_{speakerName}_{index}.wav` Example: 7_jackson_32.wav\n",
        "\n",
        "### Usage\n",
        "The test set officially consists of the first 10% of the recordings. Recordings numbered 0-4 (inclusive) are in the test and 5-49 are in the training set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hym3z8vEcxKr"
      },
      "outputs": [],
      "source": [
        "# clone git repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7Omd4w7Txed"
      },
      "outputs": [],
      "source": [
        "#check file list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-48uVgzi6-z"
      },
      "outputs": [],
      "source": [
        "#chekc file list in dir"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "acquire_data  metadata.py\t    README.md\tupload_to_hub.py\n",
        "__init__.py   pip_requirements.txt  recordings\tutils\n",
        "```\n",
        "\n",
        "`recodingds` : 디렉토리에 음성 파일들이 위치"
      ],
      "metadata": {
        "id": "eOi2-QJThf4m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aj5s7ZcRdqjm"
      },
      "outputs": [],
      "source": [
        "#collect list of file using pathlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check Path"
      ],
      "metadata": {
        "id": "2gsnu_p7ozRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "audio파일들의 Path를 확인"
      ],
      "metadata": {
        "id": "GiTBXCJchyd4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQdZUsvik1O6"
      },
      "outputs": [],
      "source": [
        "#Path, name, stem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae1MLzRMM_Uh"
      },
      "source": [
        "## `ipd.Audio`를 이용한 `wav`파일 들어보기\n",
        "\n",
        "```\n",
        "??ipd.Audio\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "??ipd.Audio"
      ],
      "metadata": {
        "id": "TO9RyBdhpj-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYpcwCr8drP1"
      },
      "outputs": [],
      "source": [
        "#listen audio file using ipd.Audio"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Audio Meta data\n",
        "\n",
        "- `sample_rate` is the sampling rate of the audio\n",
        "- `num_channels` is the number of channels\n",
        "- `num_frames` is the number of frames per channel\n",
        "- `bits_per_sample` is bit depth\n",
        "- `encoding` is the sample coding format"
      ],
      "metadata": {
        "id": "S8-8DFg6UtMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#audio meta data check \n",
        "# torchaudio.info"
      ],
      "metadata": {
        "id": "S8TcQsI-Uglh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OO97OopnM8vF"
      },
      "source": [
        "## torchaudio를 이용하여 음악파일 불러오기\n",
        "### Loading audio data\n",
        "To load audio data, you can use `torchaudio.load()`.\n",
        "\n",
        "This function accepts a path-like object or file-like object as input.\n",
        "\n",
        "The returned value is a tuple of waveform (`Tensor`) and sample rate (`int`).\n",
        "\n",
        "By default, the resulting tensor object has `dtype=torch.float32` and its value range is` [-1.0, 1.0]`.\n",
        "\n",
        "For the list of supported format, please refer to the torchaudio documentation.\n",
        "```\n",
        "waveform, sample_rate = torchaudio.load(SAMPLE_WAV)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "??torchaudio.load"
      ],
      "metadata": {
        "id": "HFa1sBiKqbma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlkrpqbxuHEE"
      },
      "outputs": [],
      "source": [
        "#load audio to tensor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check sampling rate"
      ],
      "metadata": {
        "id": "q6I4jePXqxOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check samples"
      ],
      "metadata": {
        "id": "sTt11njkq2A_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check type of samples"
      ],
      "metadata": {
        "id": "U64qYeUKiQla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSIHs_8HuG8U"
      },
      "outputs": [],
      "source": [
        "#check shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check file duration(second)"
      ],
      "metadata": {
        "id": "Vx-i5Pffq8cR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mono to stereo"
      ],
      "metadata": {
        "id": "i3Cxf_vKrPJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#stereo to mono"
      ],
      "metadata": {
        "id": "IIhmb5sVrUbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tensor slicing"
      ],
      "metadata": {
        "id": "36oNrJlIrDeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bipxsg9gNmYo"
      },
      "source": [
        "마찬가지로 `ipd.Audio`를 이용해서도 `torch.Tensor`타입의 변수를 읽고 들을 수 있음."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "??ipd.Audio"
      ],
      "metadata": {
        "id": "pqzldUBxrf6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7ObXPQruMuE"
      },
      "outputs": [],
      "source": [
        "#listen audio using tensor and ipd.audio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKnzVtnFNzGr"
      },
      "source": [
        "## torch.Tensor타입의 Waveform의 시각화 \n",
        "`matplotlib.pyplot` 을 이용하여 audio sample을 시각화 가능\n",
        "\n",
        "python의 `Slicing`을 통해 특정구간을 확대하여 확인 가능\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = list(torch.sin(torch.tensor(range(10))))\n",
        "data"
      ],
      "metadata": {
        "id": "Y3zafngbr66x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(data)"
      ],
      "metadata": {
        "id": "mlL0RYpFsA7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y[0]"
      ],
      "metadata": {
        "id": "cOoMWkEqsPQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(y[0])"
      ],
      "metadata": {
        "id": "Fz8tOMCoi03z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start,end = 100,150\n",
        "plt.plot(y[0])\n",
        "plt.axvline(start,color='r')\n",
        "plt.axvline(end,color='r')"
      ],
      "metadata": {
        "id": "ImPieszTjAm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJluwxMRuVcr"
      },
      "outputs": [],
      "source": [
        "plt.plot(y[0][0:1024])\n",
        "plt.plot(torch.hann_window(1024))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = y[0][0:1024]*torch.hann_window(1024)"
      ],
      "metadata": {
        "id": "FYjG4ohJvIh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(y[0][0:1024])"
      ],
      "metadata": {
        "id": "M4pw5_rwvTKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(data)"
      ],
      "metadata": {
        "id": "OkrmFq1uvOV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.hann_window(1024)"
      ],
      "metadata": {
        "id": "3FC_9LL3u4wr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UtRWhTkWu4k_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start,dur = 1000,150\n",
        "#plt.bar(range(dur),y[0][start:start+dur])\n",
        "plt.figure(figsize=(10,2),dpi=100)\n",
        "plt.plot(range(dur),y[0][start:start+dur])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j5LKVp7q5yLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `matplotlib.pyplot.stem` 을 이용하여 sample확인\n",
        "https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.stem.html\n",
        "```python\n",
        "??matplotlib.pyplot.stem\n",
        "```"
      ],
      "metadata": {
        "id": "jePkB4ABjlFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,2),dpi=100)\n",
        "plt.stem(range(dur),y[0][start:start+dur], use_line_collection=True)"
      ],
      "metadata": {
        "id": "3thQN4VbjjsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "plot과 함께 그리기"
      ],
      "metadata": {
        "id": "Puk2mfxgj__b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#plt.bar(range(dur),y[0][start:start+dur])\n",
        "plt.figure(figsize=(10,2),dpi=100)\n",
        "plt.plot(range(dur),y[0][start:start+dur])\n",
        "plt.show()\n",
        "plt.figure(figsize=(10,2),dpi=100)\n",
        "plt.plot(range(dur),y[0][start:start+dur])\n",
        "plt.stem(range(dur),y[0][start:start+dur], use_line_collection=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NtoOo7ms3JvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0og0PR2OkfU"
      },
      "source": [
        "## Audio feature extraction \n",
        "### Overview of audio features\n",
        "\n",
        "<img src=\"https://download.pytorch.org/torchaudio/tutorial-assets/torchaudio_feature_extractions.png\" width=600>\n",
        "\n",
        "\n",
        "\n",
        "frequncy Domain\n",
        "\n",
        "STFT (DFT)\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/6/61/FFT-Time-Frequency-View.png?20171130134719\" width=600>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KpqHM3OtJTap"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oahISA1O6Pp"
      },
      "source": [
        "### Raw Spectrogram \n",
        "`torchaudio.transforms.Spectrogram` class를 이용 `T.Spectrogram`\n",
        "```python\n",
        "n_fft = 1024\n",
        "win_length = None\n",
        "hop_length = 512\n",
        "\n",
        "# Define transform\n",
        "spectrogram = T.Spectrogram(\n",
        "    n_fft=n_fft,\n",
        "    win_length=win_length,\n",
        "    hop_length=hop_length,\n",
        "    center=True,\n",
        "    pad_mode=\"reflect\",\n",
        "    power=2.0,\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "??T.Spectrogram"
      ],
      "metadata": {
        "id": "FQ537V53lvHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(audios[1])\n",
        "y,sr = torchaudio.load(audios[1])\n",
        "print(y.shape)\n",
        "plt.plot(y[0])\n"
      ],
      "metadata": {
        "id": "Hy3jqRmul_EU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(y[0][0:1024])"
      ],
      "metadata": {
        "id": "O5N_d-jmmMQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_fft=256\n",
        "win_length = n_fft\n",
        "hop_length=win_length//2\n",
        "start,dur = 0,2911\n",
        "plt.figure(figsize=(16,1),dpi=300)\n",
        "plt.plot(y[0][start:start+dur])\n",
        "i=0\n",
        "\n",
        "for x in range(start,dur,hop_length):\n",
        "  i+=1  \n",
        "  c='r' if i%2==0 else 'g'\n",
        "  plt.axvline(x,color=c)\n",
        "  plt.axvspan(x,x+win_length,color='r',alpha=0.1)\n"
      ],
      "metadata": {
        "id": "zjj8uyrZmR8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " plt.plot(torch.hann_window(256)) #1/2 overlap 128 "
      ],
      "metadata": {
        "id": "D1yqw0LxzhxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2iRu3PePOLM"
      },
      "outputs": [],
      "source": [
        "spec_converter = T.Spectrogram(n_fft=n_fft,\n",
        "                               win_length=win_length,\n",
        "                               hop_length=hop_length)\n",
        "spec = spec_converter(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hua6W9QPV9O"
      },
      "outputs": [],
      "source": [
        "spec.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`torch.Size([1, 129, 23])` \n",
        "\n",
        "1 : batch size or channel\n",
        "\n",
        "129 : n_fft // 2 +1 (n_fft = 256) \n",
        "\n",
        "23 : ceil(len(y) /hop_length)\n"
      ],
      "metadata": {
        "id": "InwHakE1zf48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "print(len(y[0]) )\n",
        "print(len(y[0])/hop_length )\n",
        "print(math.ceil(len(y[0])/hop_length))\n"
      ],
      "metadata": {
        "id": "EouSHRYRz8Di"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "??T.Spectrogram"
      ],
      "metadata": {
        "id": "fEdItsZB0T4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(y[0]))\n",
        "print(len(y[0])//hop_length+1)"
      ],
      "metadata": {
        "id": "RPT-3Pr0pkh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spec, spec.shape"
      ],
      "metadata": {
        "id": "FsJlPIbo0g8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d27eIA3pPlcg"
      },
      "outputs": [],
      "source": [
        "plt.plot(y[0])\n",
        "plt.show()\n",
        "plt.imshow(spec[0],origin=\"lower\",aspect='auto',interpolation='nearest')\n",
        "plt.colorbar()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_fft=256\n",
        "win_length = n_fft\n",
        "hop_length=win_length//2\n",
        "start,dur = 0,2911\n",
        "plt.figure(figsize=(16,1),dpi=300)\n",
        "plt.plot(y[0][start:start+dur])\n",
        "i=0\n",
        "\n",
        "for x in range(start,dur,hop_length):\n",
        "  i+=1  \n",
        "  c='r' if i%2==0 else 'g'\n",
        "  plt.axvline(x,color=c)\n",
        "  plt.axvspan(x,x+win_length,color='r',alpha=0.1)\n",
        "plt.show()\n",
        "plt.plot(spec[0,:,5])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3GpMcDBQsMYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyfI7VIbP6ry"
      },
      "source": [
        "### AmplitudeToDB\n",
        "Turn a tensor from the power/amplitude scale to the decibel scale.\n",
        "\n",
        "`torchaudio.transforms.AmplitudeToDB(stype: str = 'power', top_db: Optional[float] = None)`\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYfnbwTYP4kt"
      },
      "outputs": [],
      "source": [
        "db_converter = T.AmplitudeToDB()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veLfDnZaQt6Z"
      },
      "outputs": [],
      "source": [
        "db_spec = db_converter(spec)\n",
        "plt.imshow(db_spec[0],origin='lower',aspect='auto',interpolation='nearest')\n",
        "plt.colorbar()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8000 sampling rate -> 4000 hz\n",
        "\n",
        "129 bins \n",
        "\n",
        "4000/129 "
      ],
      "metadata": {
        "id": "lSIwEwLD1nUN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HtNJhqu82A3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db_spec = db_converter(spec)\n",
        "plt.imshow(db_spec[0],origin='lower',aspect='auto',interpolation='nearest')\n",
        "plt.set_yticklabel(torch.arange(129)*4000 /129)"
      ],
      "metadata": {
        "id": "W7Xn69Gp1jwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpbWeAhXuVaK"
      },
      "outputs": [],
      "source": [
        "spec.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mel-Spectrogram\n",
        "참고 : https://haythamfayek.com/2016/04/21/speech-processing-for-machine-learning.html"
      ],
      "metadata": {
        "id": "JXW5vFLKvmdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mel_scale = T.MelScale(n_mels=64,sample_rate=8000,f_min=20,f_max=4000,n_stft=129)"
      ],
      "metadata": {
        "id": "wrcpXlLX11xH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(mel_scale.fb,aspect='auto',origin='lower')"
      ],
      "metadata": {
        "id": "GD8hVS8F2FoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fb = torchaudio.functional.melscale_fbanks(n_freqs=129,\n",
        "                                           f_min=20,\n",
        "                                           f_max=4000,\n",
        "                                           n_mels=10,\n",
        "                                           sample_rate=8000)\n",
        "fb.shape"
      ],
      "metadata": {
        "id": "yuNVAb4W3Z-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  plt.plot(fb.T[5])"
      ],
      "metadata": {
        "id": "hSxxPvZe46RM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for e,bin in enumerate(fb.T) :\n",
        "  plt.plot(bin)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AeRvV3Oq2SPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uYODKfcV2FjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJBtTThweHpd"
      },
      "outputs": [],
      "source": [
        "mel_converter = T.MelSpectrogram(sample_rate=8000,n_mels=64,n_fft=256,hop_length=n_fft//2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epstwygqfYor"
      },
      "outputs": [],
      "source": [
        "mel_spec = mel_converter(y)\n",
        "plt.imshow(mel_spec[0],aspect='auto',interpolation='nearest',origin='lower')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mel_spec = db_converter(mel_spec)\n",
        "plt.imshow(mel_spec[0],aspect='auto',interpolation='nearest',origin='lower')"
      ],
      "metadata": {
        "id": "ONRAQIRb6FWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MFCC\n",
        "```python\n",
        "CLASS torchaudio.transforms.MFCC(\n",
        "        sample_rate: int = 16000, \n",
        "        n_mfcc: int = 40, \n",
        "        dct_type: int = 2, \n",
        "        norm: str = 'ortho', \n",
        "        log_mels: bool = False, \n",
        "        melkwargs: Optional[dict] = None)\n",
        "```"
      ],
      "metadata": {
        "id": "GJDzQYyGuV0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "??T.MFCC"
      ],
      "metadata": {
        "id": "9yLb2Jjd41aR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "melkwargs={\n",
        "        \"n_fft\":256,\n",
        "        \"n_mels\": 64,\n",
        "        \"hop_length\": 256//2,\n",
        "        \"mel_scale\": \"htk\",\n",
        "    }\n",
        "mfcc_converter = T.MFCC(sample_rate=8000,n_mfcc=13,melkwargs=melkwargs)"
      ],
      "metadata": {
        "id": "57UTRJy6uVnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mfcc = mfcc_converter(y)\n",
        "mfcc.shape"
      ],
      "metadata": {
        "id": "dr7KaCh2uIua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mfcc = db_converter(mfcc)\n",
        "plt.imshow(mfcc[0],origin='lower',aspect='auto',interpolation='nearest')"
      ],
      "metadata": {
        "id": "lyZELZPWuvHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XUQwNLq-vCqy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyNSnlCfx34JX/Uw1ViyQEej",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}